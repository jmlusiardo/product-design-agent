# Remote Design Reviews & Critiques: A Practical Playbook

> **Executive Summary** — This guide distills proven practices for running **remote** design reviews and critiques that are focused, safe, and outcome-oriented. It covers roles, agendas (sync & async), facilitation patterns, templates, and pitfalls to avoid—drawing on guidance from Figma, zeroheight, Darrin Henein, UX Collective, Foolproof, and a Notion checklist. Expect actionable checklists, time-boxed flows, and remote-first adaptations (time zones, silent feedback, Observation Mode, pods by product area). 

## Overview

- **Purpose:** Improve a design against stated goals and user needs; identify risks, trade-offs, and next steps.
- **Scope:** Remote sessions (async + synchronous); cross-functional participation (design, research, PM, eng); artifacts in shared tools.
- **Audience:** Designers and immediate collaborators; stakeholders when the session’s goal requires their input.
- **Success Criteria / KPIs:**
  - Presenter leaves unblocked with clear decisions and next steps.
  - Feedback is specific, goal-referenced, and actionable.
  - Participation is balanced across voices and time zones.

## Preparation

### Remote-First Pre-work (Presenter & Facilitator)

- Create a **pre-read** (share 24–48h ahead):
  - Problem statement, goals, success metrics.
  - Target users, scenarios, constraints, known risks.
  - Stage of work (e.g., 30/60/90%) and what feedback you seek **now**.
  - Links to prototypes/frames and prior research notes.
- Define the **feedback scope** explicitly:
  - **Seeking:** e.g., information architecture, empty states, content tone.
  - **Not seeking:** e.g., brand polish, non-critical microcopy.
- Curate the **audience**:
  - 3–7 active critiquers with relevant context.
  - Stakeholders invited when aligned to the session goal; otherwise separate review.
- Confirm **roles**: Presenter, Facilitator, Notetaker, Critiquers.
- Set up a shared **workspace**:
  - Crit board with columns (Clarifying Qs → Feedback → Risks → Actions).
  - Commenting enabled on design files; clear tagging conventions.
- Logistics:
  - Time-zone inclusive slot; recording and auto-transcription on.
  - Accessibility (captions, color-safe assets, adequate contrast).
  - Backup plan if prototypes fail (screenshots, short clips).

### Golden Rules Checklist (pin in the doc)

- [ ] Start with **problem, goals, users**, and constraints.
- [ ] State **stage** (30/60/90) and **specific asks**.
- [ ] Walk through **from the user’s entry point**.
- [ ] Keep critique about **goals and evidence**, not personal taste.
- [ ] Separate **understanding questions** from **feedback**.
- [ ] Capture **decisions, owners, due dates** live.
- [ ] Close with a **clear action list** and follow-up plan.

## Main Flow / Process

### Option A — Synchronous Remote Crit (60 minutes)

1) **Opening (5 min)**
   - Facilitator sets the goal, agenda, norms, and time boxes; confirms roles.
2) **Presenter Context (8–10 min)**
   - Problem, goals, users, stage, constraints; “Seeking / Not Seeking” slide first.
3) **Silent Scan (5 min)**
   - Everyone reviews independently; add clarifying questions and initial notes in the board to reduce anchoring.
4) **Clarifying Questions (3–5 min)**
   - Only to establish shared understanding; defer solutions.
5) **Feedback Round (20 min)**
   - Round-robin or moderated popcorn; critique links to goals and evidence.
   - Notetaker clusters themes; capture risks and assumptions explicitly.
6) **Focused Deep-Dive (10 min, optional)**
   - Short breakout(s) on a thorny issue; each group returns with 1–2 options or trade-offs.
7) **Wrap-up (5 min)**
   - Presenter restates decisions, open questions, owners, and dates; agree on follow-up channel.

### Option B — Asynchronous Crit (24–72 hours)

- **Kickoff post:** goal, context, links, due date, how to contribute, and tagging.
- **Contributions:** reviewers add goal-tied comments, questions, and alternatives (no directives).
- **Synthesis:** cluster themes; document decisions and actions; optionally schedule a 15-min sync to close.

## Roles & Responsibilities


- **Presenter**
  - Tell the story (problem → user → goals → constraints).
  - Ask for targeted feedback; listen actively; avoid defending in the moment.
- **Critiquers**
  - Offer **objective, specific, actionable** feedback tied to goals and user impact.
  - Prefer questions and rationale over prescriptive solutions.
- **Facilitator**
  - Curate attendees; enforce norms and time; ensure balanced participation.
  - Intervene on derailments (solutioneering, tangents, dominance).
- **Notetaker**
  - Capture key points, decisions, risks, and actions in a visible doc.
  - Post recap promptly with owners and dates.

## Templates / Canvases / Frameworks

### 1. Remote Crit Frame (for the first slide or top of the doc)

- **Title & Date**
- **Problem & Goals**
- **Users & Scenarios**
- **Stage (30/60/90)**
- **Seeking / Not Seeking**
- **Key Insights & Constraints**
- **Open Questions**
- **Risks & Assumptions**
- **Next Steps (draft)**

### 2. Crit Board (for async and live)

- Columns: **Clarifying Qs → Feedback → Risks → Actions**.
- Silent-first notes; dot-vote to prioritize if needed.
- Label each item with the frame/screen ID for traceability.

### 3. Method Picker (choose per maturity & goal)

- **Standard Crit:** context → clarifying → feedback → wrap.
- **Jam / Divergent Crit:** early-stage; generate alternatives collaboratively, then converge.
- **Pair / Small-Group Crit:** deep problem areas; quick breakout then share-back.

## Aftermath / Follow-ups

- **Recap package** (post within 24h):
  - Recording + transcript; design file links.
  - Decisions, rejected options (and why), open questions.
  - Actions with owners and dates; risks and mitigation notes.
- **Change log:** maintain a lightweight log in the design doc for future context.
- **Ritual health:** track attendance, diversity of voices, and action completion; adjust cadence and format based on signals.

## Best Practices & Pitfalls

### Do

- Tie every comment to a **goal, user outcome, or constraint**.
- Prefer **questions** (“What evidence supports X?”) to assertions.
- Normalize **work-in-progress**; make it safe to show incomplete ideas.
- Use **async** for context-heavy work and time-zones; a short sync to close loops.

### Avoid

- **Bikeshedding** (dwelling on low-impact details); time-box and park.
- **Solutioneering** inside the crit; note options for follow-up exploration.
- **Vague feedback** (“doesn’t feel right”); ask for the underlying goal/heuristic.
- **Dominance effects**; facilitators rotate speakers and invite quieter voices.

## Tools & Resources

- **Core stack:** shared design files with comments, collaborative boards for notes, meeting platform with recording and captions, async doc for pre-reads and recaps.
- **Optional:** lightweight voting (to prioritize issues, not to “approve” designs), linkable screen/flow IDs for precise references.

## FAQ / Quick Answers

- **What’s the difference between critique and approval?**  
  Critique evaluates against goals and evidence; approval is a separate governance decision.
- **How many attendees?**  
  Enough context, minimal noise: typically 3–7 active voices plus observers if needed.
- **How often?**  
  Weekly or bi-weekly; aim for ~60 minutes live or 24–72h async windows.
- **Stakeholders?**  
  Invite when aligned to the session goal; otherwise run dedicated stakeholder reviews.

## References
- Design Critiques at Figma — six methods: https://nlevin.medium.com/design-critiques-at-figma-799d4a3a1b0
- Practical Design Critique — Darrin Henein: https://darrinhenein.com/2017/practical-design-critique
- How to run an effective design critique — zeroheight: https://zeroheight.com/blog/how-to-run-an-effective-design-critique/
- Design critique — checklists & framework — Jonny Czar (UX Collective): https://uxdesign.cc/design-critique-design-better-products-through-team-collaboration-4c4f26a7be5f
- The Pool Rules of Design Critique — Foolproof: https://foolproof.co.uk/journal/the-pool-rules-of-design-critique/
- Critiquing our (remote) design crits — Aletheia Delivre (UX Collective): https://uxdesign.cc/critiquing-our-remote-design-crits-2410564707f1
- 6 anti-behaviours in design critique — Prototypr: https://blog.prototypr.io/6-anti-behaviours-in-design-critique-and-how-to-handle-them-a39ad5ca885