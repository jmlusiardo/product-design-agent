# Moderating Usability Tests: A Complete Facilitation Guide

> **Executive Summary** — This guide provides a comprehensive framework for planning, conducting, and following up on moderated usability tests. It covers preparation, participant introduction, facilitation techniques, common problems and solutions, and quality assurance measures. The focus is on gathering unbiased insights through proper moderation while maintaining test rigor and participant comfort.

## Overview & Objectives

- **Purpose:** Enable researchers to facilitate effective usability tests that generate reliable, actionable insights about user behavior and product usability
- **Scope:** Covers remote and in-person moderated testing, from preparation through analysis
- **Audience:** UX researchers, product managers, designers conducting moderated usability tests
- **Success Criteria:**
  - Unbiased participant behavior and feedback
  - Reliable data collection through proper observation techniques
  - Comfortable test environment that encourages natural user behavior
  - Actionable insights that inform design decisions

## Prerequisites & Preparation

### Test Planning Requirements
Before moderating, ensure you have completed:
- [ ] Test objectives and hypotheses defined
- [ ] Participant recruitment and screening completed
- [ ] Task scenarios written from user perspective
- [ ] Testing environment prepared (tools, devices, materials)
- [ ] Observer team briefed on roles and protocols

> **Cross-reference:** For complete test planning guidance, see `usability_testing.md` and `evaluation_type.md` in the task registry.

### Pre-Test Checklist

#### Remote Testing Setup
- [ ] Remote testing platform ready (UserTesting, Loop11, Silverback 2.0)
- [ ] Screen sharing and recording configured
- [ ] Backup communication method available
- [ ] Test tasks accessible to participants

#### In-Person Testing Setup
- [ ] All materials in place (devices, prototypes, chargers, task sheets)
- [ ] Proper lighting for screen visibility
- [ ] Extra devices and chargers available
- [ ] Note-taking materials and observers prepared
- [ ] Context camera positioned (for mobile testing)

### Conducting a Dry Run

**Critical step:** Always run a pilot test before live sessions.

**Validation points:**
- [ ] All tasks can be performed successfully
- [ ] Flows with errors identified and documented
- [ ] Session timing measured and adjusted
- [ ] Hardware/software functionality verified
- [ ] Moderator understands system limitations

## Preparing Observers

### Training Requirements
1. **Distinguish observations from opinions**
   - Observers must understand the difference between what they see and what they interpret
   - Use the principle: "Am I observing or am I judging?"
   - Focus on user actions and verbatim quotes, not assumptions about intent

2. **Ensure team participation**
   - Every team member should attend at least one testing session
   - Provide individual calendar invites with note-taking document access
   - Assign specific observation roles to different team members

## Introducing Participants to the Test

### Standard Introduction Script

Use this structure for consistent participant onboarding:
INSTRUCTIONS TO THE USER:

Thank you for helping us.
Purpose of evaluation (here to get your feedback
on design. No right or wrong answers).
Use these tasks (Test Packet) - 17pt font task
scenarios Word doc for user) to find the answer on
the site.
Think Out Loud so I can follow along (tell me what
you are thinking and feeling).
Go on to next task when ready (move at your own
pace when you feel you found the answer).
Questions afterward when you are done. If have
questions won't be able to answer but will do my
best at end to answer them.

### Key Messaging Points

1. **Express gratitude**
   - Set positive tone from the start
   - Show appreciation for participant's time
   - Creates collaborative atmosphere

2. **Explain the purpose**
   - Emphasize you want honest feedback about the product
   - Clarify that you're testing the product, not them
   - Stress there are no right or wrong answers
   - Make participants understand their role

3. **Emphasize think-aloud protocol**
   - Request continuous verbalization of thoughts and feelings
   - Explain you want to understand their thought processes
   - Ask them to voice even small details about their actions

4. **Set task expectations**
   - Explain they'll receive a series of tasks to perform
   - Clarify they should work through tasks one at a time
   - Encourage them to move at their own pace

5. **Defer questions**
   - Request that questions be saved until the end
   - Explain this helps simulate real-life usage
   - Assure them you'll address questions at the conclusion

6. **Provide task materials**
   - Give each task on separate paper for focus
   - Ensure font size is large enough to read easily
   - Keep tasks visible and accessible

## Core Facilitation Principles

### The "Keep in Mind" Framework

**We're testing the app, not you**
- This isn't a test of participant skills or intelligence
- No wrong or right answers exist
- Focus remains on product evaluation

**You won't be using the real app**
- Clarify this is a prototype, not the final application
- Some features might not work as expected
- Set appropriate expectations about functionality

**Say aloud**
- Encourage continuous verbalization of thoughts and actions
- Request "as much as possible" communication
- Click anywhere to continue when moderator indicates

### Maintaining Neutrality

**Use monotone delivery**
- Avoid inflection that suggests approval or disapproval
- Keep emotional reactions hidden from participants
- Maintain consistent, neutral tone throughout

**Standard neutral responses:**
- "Aha" and "OK" for acknowledgment
- "You help us identifying what we were looking for"
- Avoid leading participants toward specific actions

**Stay relaxed**
- Your energy affects participant comfort
- Calm moderator = calm participant
- Manage your own stress to maintain test quality

## Advanced Facilitation Techniques

### Clarification Techniques (Minimal Bias)

#### Echo Technique
**Purpose:** Clarify without suggesting or judging
**Method:** Repeat participant's exact words in question form
**Example:** 
- Participant: "This is not how I do things"
- Moderator: "This is not how you do things?"

#### Boomerang Technique  
**Purpose:** Deflect user questions without providing answers
**Method:** Return question with neutral question
**Example:**
- Participant: "Is it even possible to do this?"
- Moderator: "What do you think?"

#### Columbo Technique
**Purpose:** Gather specific information without leading
**Method:** Start indicating something, expecting user to complete the thought
**Example:** Begin statement and let participant finish, avoiding direct leading

### Managing Silence

**Don't rush to fill silence**
- Resist the urge to talk when participants pause
- Allow thinking time - participants often volunteer additional information
- Count to 7 before intervening
- Silence often produces the most valuable insights

## Common Problems & Solutions

### Participant Behavior Issues

| Problem | Solution |
|---------|----------|
| **Participant struggles significantly** | Let them struggle longer than comfortable before intervening. If they give up, move to next task. |
| **Participant stays silent** | Politely ask: "Remember to think out loud so I can follow along" |
| **Think-aloud feels awkward** | Follow up everything they say with "okay", "uh-huh" to encourage continued talking |
| **Participant feels insecure** | Say: "There are no right or wrong answers" or "You helped us identify what we were looking for" |
| **Waits for permission** | Remind: "Move at your own pace during the test" |
| **Mumbles or speaks unclearly** | Politely ask them to speak louder and repeat if needed |
| **Asks how product works** | Use reverse questions: "Is this what you expect to find there?" |
| **Requests help moving forward** | Ask them to try more. If impossible, move to next task with explanation at end |
| **Wants validation** | Repeat: "You're helping us identify what we're looking for" |
| **Panicking for help** | Let them struggle within reason. Say nothing or "OK" |

## What NOT to Do

### Avoid These Moderator Mistakes

- **Don't underestimate the power of observation**
- **Don't provide feedback on future behavior**
- **Don't ask leading questions** that insert your bias
- **Don't answer "What will this do?" questions** - ask "What do you expect it to do?"
- **Don't jump in to help too quickly**
- **Don't prompt the user**
- **Don't minimize realistic distractions** (especially mobile testing)

### Leading vs. Neutral Questions

❌ **Leading:** "Do you think this button is confusing?"
✅ **Neutral:** "What do you think about this button?"

❌ **Leading:** "Would you click here next?"  
✅ **Neutral:** "What would you do next?"

## Quality Observation & Data Collection

### Expected User Behaviors

When analyzing usability issues, expect users to experience:

1. **Not seeing something** (visibility problems)
2. **Going in wrong direction** (navigation issues)
3. **Thinking it's correct when it isn't** (false feedback)
4. **Missing a "rule"** (mental model mismatches)

### Recording Methods

Track these quantitative measures:
- **Number of confusions** per task
- **Number of errors** per task  
- **Number of highlights** (positive moments)

### Qualitative Data Collection

- **Write down quotable quotes** verbatim
- **Note struggle areas and pain points**
- **Observe body language and emotional reactions**
- **Document context of user actions**

## Ensuring Test Rigor

### Credibility (Internal Validity)
- Write scenarios reflecting user's perspective
- Use think-aloud protocol for direct impressions
- Focus on direct observations vs. indirect reports
- Check conclusions with users through teach-back or post-scenario interviews

### Transferability (External Validity)  
- Select participants matching end-user criteria
- Write scenarios involving realistic tasks
- Use typical platforms and equipment
- Test with realistic prototypes and documentation

### Dependability (Reliability)
- Use observation team with multiple perspectives
- Retest to verify improvements
- Consider external consultant review of process and findings

## Cultural Considerations

### Respectful Facilitation
- **Be considerate of local manners** and participant context
- **Make participants feel honored** for their contribution
- **Wait for patterns** - don't jump to conclusions after limited sessions
- **Beware of biased first judgments**
- **Keep test environment realistic** when possible

### Mobile Testing Specifics
- **Allow realistic distractions** during mobile testing
- **Use context camera** to capture field of view perception
- **Consider environmental factors** affecting mobile usage

## Post-Session Protocol

### Immediate Actions
- Thank participants again for their contribution
- Address any questions they saved for the end
- Ensure all recordings and notes are properly saved
- Brief observers on key observations while fresh

### Documentation Requirements
- Compile observer notes and recordings
- Note any technical issues that affected the session
- Document participant quotes and behavioral observations
- Prepare findings for analysis phase

> **Cross-reference:** For comprehensive guidance on analyzing and reporting results, see `reporting_test_results.md` in the task registry.

## Remote vs. In-Person Considerations

### Remote Testing Advantages
- Access to geographically diverse participants
- Natural environment testing
- Easier scheduling and logistics
- Cost-effective for multiple sessions

### Remote Testing Challenges
- Technical difficulties can disrupt flow
- Limited ability to observe full context
- Harder to read participant body language
- Potential for home environment distractions

### In-Person Testing Advantages
- Better observation of full user context
- Easier to manage technical issues
- More natural facilitator-participant interaction
- Enhanced ability to capture emotional reactions

## Tools & Resources

### Remote Testing Tools
- **UserTesting:** Comprehensive remote testing platform
- **Loop11:** Task-based remote usability testing
- **Silverback 2.0:** Screen recording and observation

### Documentation Tools
- Note-taking templates for observers
- Recording equipment for session capture
- Task scenario templates
- Observer briefing materials

## Success Metrics

### Session Quality Indicators
- Participants speak freely and naturally
- Tasks completed without excessive moderator intervention
- Rich qualitative insights captured
- Minimal technical disruptions
- Observer team captures diverse perspectives

### Moderator Performance
- Maintains neutrality throughout session
- Uses appropriate clarification techniques
- Allows natural participant behavior
- Collects both quantitative and qualitative data
- Creates comfortable environment for honest feedback

## References
- Checklist for Moderating a Usability Test: https://www.nngroup.com/articles/usability-checklist/
- Moderating Usability Tests: https://www.sciencedirect.com/book/9780123739339/moderating-usability-tests
- Moderated Usability Testing: A Tactical Guide: https://www.looppanel.com/blog/moderated-usability-testing-a-tactical-guide
- How to lead and Moderate a Usability Test: https://www.emergobyul.com/news/how-lead-and-moderate-usability-test